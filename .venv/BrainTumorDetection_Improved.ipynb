{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "import-libraries",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Importieren der notwendigen Bibliotheken\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dataset-class",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset-Klasse für Gehirntumor-Bilder\n",
    "class BrainTumorDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Initialisiert den Dataset für Gehirntumor-Klassifikation.\n",
    "        Args:\n",
    "        - image_dir: Pfad zum Ordner 'data', der die Unterordner 'yes/' und 'no/' enthält.\n",
    "        - transform: Transformationen für die Vorverarbeitung.\n",
    "        \"\"\"\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.transform = transform\n",
    "\n",
    "        # Pfade zu den Unterordnern \"yes\" (Tumor) und \"no\" (Healthy)\n",
    "        tumor_dir = Path('data/yes/*.jpg') / \"yes\"\n",
    "        healthy_dir = Path('data/no/*.jpg') / \"no\"\n",
    "\n",
    "        # Bilder aus \"yes\" (Tumor) mit Label 1\n",
    "        self.image_paths.extend(tumor_dir.rglob(\"*.jpg\"))\n",
    "        self.labels.extend([1] * len(list(tumor_dir.rglob(\"*.jpg\"))))\n",
    "\n",
    "        # Bilder aus \"no\" (Healthy) mit Label 0\n",
    "        self.image_paths.extend(healthy_dir.rglob(\"*.jpg\"))\n",
    "        self.labels.extend([0] * len(list(healthy_dir.rglob(\"*.jpg\"))))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Transformationen für die Datenvorbereitung\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "model-definition",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Transfer Learning Modell mit ResNet-18\n",
    "class TransferLearningModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TransferLearningModel, self).__init__()\n",
    "        self.base_model = models.resnet18(pretrained=True)\n",
    "        for param in self.base_model.parameters():\n",
    "            param.requires_grad = False\n",
    "        num_features = self.base_model.fc.in_features\n",
    "        self.base_model.fc = nn.Sequential(\n",
    "            nn.Linear(num_features, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.base_model(x)\n",
    "\n",
    "# Initialisierung von Modell, Loss-Funktion und Optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = TransferLearningModel().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.base_model.fc.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "training-validation",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Trainings- und Validierungsprozess\n",
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=10):\n",
    "    \"\"\"\n",
    "    Trainiert das Modell und validiert es in jedem Epoch.\n",
    "    Args:\n",
    "    - model: Das zu trainierende Modell.\n",
    "    - dataloaders: Dictionary mit 'train' und 'val' Dataladern.\n",
    "    - criterion: Loss-Funktion.\n",
    "    - optimizer: Optimizer für das Training.\n",
    "    - num_epochs: Anzahl der Epochen.\n",
    "    \"\"\"\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(\"-\" * 10)\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "            print(f\"{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "data-prep-training",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gesamtanzahl der Bilder im Dataset: 800\n",
      "Anzahl der Tumor-Bilder: 392\n",
      "Anzahl der gesunden Bilder: 408\n",
      "Anzahl der Trainings-Samples: 640\n",
      "Anzahl der Validierungs-Samples: 160\n",
      "Epoch 1/40\n",
      "----------\n",
      "train Loss: 0.4796 Acc: 0.7828\n",
      "val Loss: 0.2580 Acc: 0.9125\n",
      "Epoch 2/40\n",
      "----------\n",
      "train Loss: 0.3337 Acc: 0.8562\n",
      "val Loss: 0.1754 Acc: 0.9375\n",
      "Epoch 3/40\n",
      "----------\n",
      "train Loss: 0.3033 Acc: 0.8672\n",
      "val Loss: 0.1972 Acc: 0.9250\n",
      "Epoch 4/40\n",
      "----------\n",
      "train Loss: 0.2822 Acc: 0.8859\n",
      "val Loss: 0.1775 Acc: 0.9500\n",
      "Epoch 5/40\n",
      "----------\n",
      "train Loss: 0.2306 Acc: 0.9031\n",
      "val Loss: 0.1114 Acc: 0.9625\n",
      "Epoch 6/40\n",
      "----------\n",
      "train Loss: 0.2423 Acc: 0.8938\n",
      "val Loss: 0.1300 Acc: 0.9563\n",
      "Epoch 7/40\n",
      "----------\n",
      "train Loss: 0.2619 Acc: 0.8969\n",
      "val Loss: 0.1553 Acc: 0.9250\n",
      "Epoch 8/40\n",
      "----------\n",
      "train Loss: 0.2461 Acc: 0.9062\n",
      "val Loss: 0.1494 Acc: 0.9375\n",
      "Epoch 9/40\n",
      "----------\n",
      "train Loss: 0.2062 Acc: 0.9250\n",
      "val Loss: 0.0927 Acc: 0.9750\n",
      "Epoch 10/40\n",
      "----------\n",
      "train Loss: 0.2079 Acc: 0.9203\n",
      "val Loss: 0.1429 Acc: 0.9313\n",
      "Epoch 11/40\n",
      "----------\n",
      "train Loss: 0.1840 Acc: 0.9219\n",
      "val Loss: 0.1537 Acc: 0.9313\n",
      "Epoch 12/40\n",
      "----------\n",
      "train Loss: 0.2229 Acc: 0.9156\n",
      "val Loss: 0.0834 Acc: 0.9875\n",
      "Epoch 13/40\n",
      "----------\n",
      "train Loss: 0.1411 Acc: 0.9328\n",
      "val Loss: 0.0752 Acc: 0.9750\n",
      "Epoch 14/40\n",
      "----------\n",
      "train Loss: 0.1982 Acc: 0.9172\n",
      "val Loss: 0.1423 Acc: 0.9313\n",
      "Epoch 15/40\n",
      "----------\n",
      "train Loss: 0.1728 Acc: 0.9328\n",
      "val Loss: 0.0774 Acc: 0.9688\n",
      "Epoch 16/40\n",
      "----------\n",
      "train Loss: 0.1682 Acc: 0.9391\n",
      "val Loss: 0.1062 Acc: 0.9500\n",
      "Epoch 17/40\n",
      "----------\n",
      "train Loss: 0.1626 Acc: 0.9328\n",
      "val Loss: 0.0719 Acc: 0.9812\n",
      "Epoch 18/40\n",
      "----------\n",
      "train Loss: 0.1622 Acc: 0.9266\n",
      "val Loss: 0.0678 Acc: 0.9688\n",
      "Epoch 19/40\n",
      "----------\n",
      "train Loss: 0.1764 Acc: 0.9250\n",
      "val Loss: 0.0691 Acc: 0.9812\n",
      "Epoch 20/40\n",
      "----------\n",
      "train Loss: 0.1469 Acc: 0.9469\n",
      "val Loss: 0.0732 Acc: 0.9688\n",
      "Epoch 21/40\n",
      "----------\n",
      "train Loss: 0.1237 Acc: 0.9516\n",
      "val Loss: 0.0588 Acc: 0.9812\n",
      "Epoch 22/40\n",
      "----------\n",
      "train Loss: 0.1367 Acc: 0.9391\n",
      "val Loss: 0.0588 Acc: 0.9812\n",
      "Epoch 23/40\n",
      "----------\n",
      "train Loss: 0.1728 Acc: 0.9344\n",
      "val Loss: 0.0870 Acc: 0.9500\n",
      "Epoch 24/40\n",
      "----------\n",
      "train Loss: 0.0850 Acc: 0.9750\n",
      "val Loss: 0.0472 Acc: 0.9812\n",
      "Epoch 25/40\n",
      "----------\n",
      "train Loss: 0.1346 Acc: 0.9516\n",
      "val Loss: 0.0688 Acc: 0.9750\n",
      "Epoch 26/40\n",
      "----------\n",
      "train Loss: 0.1270 Acc: 0.9547\n",
      "val Loss: 0.0700 Acc: 0.9750\n",
      "Epoch 27/40\n",
      "----------\n",
      "train Loss: 0.1223 Acc: 0.9563\n",
      "val Loss: 0.0621 Acc: 0.9812\n",
      "Epoch 28/40\n",
      "----------\n",
      "train Loss: 0.1396 Acc: 0.9453\n",
      "val Loss: 0.0978 Acc: 0.9688\n",
      "Epoch 29/40\n",
      "----------\n",
      "train Loss: 0.1103 Acc: 0.9500\n",
      "val Loss: 0.0720 Acc: 0.9750\n",
      "Epoch 30/40\n",
      "----------\n",
      "train Loss: 0.1541 Acc: 0.9469\n",
      "val Loss: 0.0854 Acc: 0.9750\n",
      "Epoch 31/40\n",
      "----------\n",
      "train Loss: 0.1131 Acc: 0.9563\n",
      "val Loss: 0.0530 Acc: 0.9812\n",
      "Epoch 32/40\n",
      "----------\n",
      "train Loss: 0.1090 Acc: 0.9578\n",
      "val Loss: 0.0628 Acc: 0.9812\n",
      "Epoch 33/40\n",
      "----------\n",
      "train Loss: 0.1398 Acc: 0.9453\n",
      "val Loss: 0.0652 Acc: 0.9812\n",
      "Epoch 34/40\n",
      "----------\n",
      "train Loss: 0.1152 Acc: 0.9531\n",
      "val Loss: 0.0636 Acc: 0.9750\n",
      "Epoch 35/40\n",
      "----------\n",
      "train Loss: 0.1050 Acc: 0.9594\n",
      "val Loss: 0.0424 Acc: 0.9875\n",
      "Epoch 36/40\n",
      "----------\n",
      "train Loss: 0.1041 Acc: 0.9625\n",
      "val Loss: 0.0927 Acc: 0.9688\n",
      "Epoch 37/40\n",
      "----------\n",
      "train Loss: 0.0829 Acc: 0.9672\n",
      "val Loss: 0.0446 Acc: 0.9812\n",
      "Epoch 38/40\n",
      "----------\n",
      "train Loss: 0.1248 Acc: 0.9609\n",
      "val Loss: 0.0804 Acc: 0.9812\n",
      "Epoch 39/40\n",
      "----------\n",
      "train Loss: 0.0802 Acc: 0.9734\n",
      "val Loss: 0.0619 Acc: 0.9688\n",
      "Epoch 40/40\n",
      "----------\n",
      "train Loss: 0.0879 Acc: 0.9734\n",
      "val Loss: 0.1548 Acc: 0.9313\n"
     ]
    }
   ],
   "source": [
    "# Dataset-Klasse für Gehirntumor-Bilder\n",
    "class BrainTumorDataset(Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "        \"\"\"\n",
    "        Initialisiert den Dataset für Gehirntumor-Klassifikation.\n",
    "        Args:\n",
    "        - transform: Transformationen für die Vorverarbeitung.\n",
    "        \"\"\"\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.transform = transform\n",
    "\n",
    "        # Direktes Laden der Bildpfade\n",
    "        tumor_dir = Path('data/yes')  # Pfad zu Tumor-Bildern\n",
    "        healthy_dir = Path('data/no')  # Pfad zu gesunden Bildern\n",
    "\n",
    "        # Bilder aus \"yes\" (Tumor) mit Label 1\n",
    "        self.image_paths.extend(list(tumor_dir.rglob(\"*.jpg\")))\n",
    "        self.labels.extend([1] * len(list(tumor_dir.rglob(\"*.jpg\"))))\n",
    "\n",
    "        # Bilder aus \"no\" (Healthy) mit Label 0\n",
    "        self.image_paths.extend(list(healthy_dir.rglob(\"*.jpg\")))\n",
    "        self.labels.extend([0] * len(list(healthy_dir.rglob(\"*.jpg\"))))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "\n",
    "# Transformationen für die Datenvorbereitung\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Laden des Datasets\n",
    "dataset = BrainTumorDataset(transform=data_transforms)\n",
    "\n",
    "# Debugging: Gesamtanzahl der Bilder überprüfen\n",
    "print(f\"Gesamtanzahl der Bilder im Dataset: {len(dataset)}\")\n",
    "print(f\"Anzahl der Tumor-Bilder: {sum(label == 1 for label in dataset.labels)}\")\n",
    "print(f\"Anzahl der gesunden Bilder: {sum(label == 0 for label in dataset.labels)}\")\n",
    "\n",
    "# Prüfen, ob genügend Bilder für das Training und die Validierung vorhanden sind\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "if train_size == 0 or val_size == 0:\n",
    "    raise ValueError(\"Trainings- oder Validierungsset hat keine ausreichenden Samples!\")\n",
    "\n",
    "# Aufteilen des Datasets in Trainings- und Validierungsdaten\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# DataLoader für Training und Validierung erstellen\n",
    "dataloaders = {\n",
    "    'train': DataLoader(train_dataset, batch_size=16, shuffle=True),\n",
    "    'val': DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "}\n",
    "\n",
    "# Debugging: Überprüfen der DataLoader-Größen\n",
    "print(f\"Anzahl der Trainings-Samples: {len(train_dataset)}\")\n",
    "print(f\"Anzahl der Validierungs-Samples: {len(val_dataset)}\")\n",
    "\n",
    "# Training starten\n",
    "model = train_model(model, dataloaders, criterion, optimizer, num_epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "save-model",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modell gespeichert.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Speichern des Modells\n",
    "torch.save(model.state_dict(), \"brain_tumor_model.pth\")\n",
    "print(\"Modell gespeichert.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9c103b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Healthy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vulpe\\AppData\\Local\\Temp\\ipykernel_34676\\4132344695.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"brain_tumor_model.pth\"))  # Pfad zum gespeicherten Modell\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from pathlib import Path\n",
    "\n",
    "# Transformationen wie während des Trainings\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Modell laden\n",
    "model = TransferLearningModel()  # Erstellen Sie die Modellinstanz\n",
    "model.load_state_dict(torch.load(\"brain_tumor_model.pth\"))  # Pfad zum gespeicherten Modell\n",
    "model.eval()  # Schalten Sie das Modell in den Evaluierungsmodus\n",
    "\n",
    "# Gerät festlegen (GPU oder CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Pfad zum Testbild\n",
    "test_image_path = Path(\"data/new/image.jpg\")  # Pfad zum Testbild\n",
    "\n",
    "# Bild laden und vorbereiten\n",
    "image = Image.open(test_image_path).convert(\"RGB\")  # Bild öffnen und in RGB konvertieren\n",
    "input_tensor = data_transforms(image).unsqueeze(0).to(device)  # Transformation und Batch-Dimension hinzufügen\n",
    "\n",
    "# Vorhersage\n",
    "with torch.no_grad():\n",
    "    output = model(input_tensor)  # Modellvorhersage\n",
    "    _, predicted_class = torch.max(output, 1)  # Klasse mit der höchsten Wahrscheinlichkeit\n",
    "\n",
    "# Ausgabe der Vorhersage\n",
    "if predicted_class.item() == 1:\n",
    "    print(\"Tumor\")\n",
    "else:\n",
    "    print(\"Healthy\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
